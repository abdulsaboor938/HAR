{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# function that takes file name as input and returns a processed dataframe\n",
    "def process_file(file):\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "    # Selecting the actual required columns for further processing\n",
    "    # Selecting the actual required columns for further processing\n",
    "    data = data[[\n",
    "        'InertialMeasurementUnit RUA accX', 'InertialMeasurementUnit RUA accY', 'InertialMeasurementUnit RUA accZ',\n",
    "        'InertialMeasurementUnit RUA gyroX', 'InertialMeasurementUnit RUA gyroY', 'InertialMeasurementUnit RUA gyroZ',\n",
    "        'InertialMeasurementUnit RUA magneticX', 'InertialMeasurementUnit RUA magneticY', 'InertialMeasurementUnit RUA magneticZ',\n",
    "        'InertialMeasurementUnit RUA Quaternion1', 'InertialMeasurementUnit RUA Quaternion2', 'InertialMeasurementUnit RUA Quaternion3', 'InertialMeasurementUnit RUA Quaternion4', \n",
    "        'InertialMeasurementUnit RLA accX', 'InertialMeasurementUnit RLA accY', 'InertialMeasurementUnit RLA accZ', \n",
    "        'InertialMeasurementUnit RLA gyroX', 'InertialMeasurementUnit RLA gyroY', 'InertialMeasurementUnit RLA gyroZ',\n",
    "        'InertialMeasurementUnit RLA magneticX', 'InertialMeasurementUnit RLA magneticY', 'InertialMeasurementUnit RLA magneticZ', \n",
    "        'InertialMeasurementUnit RLA Quaternion1', 'InertialMeasurementUnit RLA Quaternion2', 'InertialMeasurementUnit RLA Quaternion3', 'InertialMeasurementUnit RLA Quaternion4',\n",
    "        'InertialMeasurementUnit LUA accX', 'InertialMeasurementUnit LUA accY', 'InertialMeasurementUnit LUA accZ',\n",
    "        'InertialMeasurementUnit LUA gyroX', 'InertialMeasurementUnit LUA gyroY', 'InertialMeasurementUnit LUA gyroZ',\n",
    "        'InertialMeasurementUnit LUA magneticX', 'InertialMeasurementUnit LUA magneticY', 'InertialMeasurementUnit LUA magneticZ',\n",
    "        'InertialMeasurementUnit LUA Quaternion1', 'InertialMeasurementUnit LUA Quaternion2', 'InertialMeasurementUnit LUA Quaternion3', 'InertialMeasurementUnit LUA Quaternion4', 'InertialMeasurementUnit LLA accX', 'InertialMeasurementUnit LLA accY', 'InertialMeasurementUnit LLA accZ', 'InertialMeasurementUnit LLA gyroX', 'InertialMeasurementUnit LLA gyroY', 'InertialMeasurementUnit LLA gyroZ', 'InertialMeasurementUnit LLA magneticX', 'InertialMeasurementUnit LLA magneticY', 'InertialMeasurementUnit LLA magneticZ', 'InertialMeasurementUnit LLA Quaternion1', 'InertialMeasurementUnit LLA Quaternion2', 'InertialMeasurementUnit LLA Quaternion3', 'InertialMeasurementUnit LLA Quaternion4',\n",
    "        'Accelerometer DOOR1 accX', 'Accelerometer DOOR1 accY', 'Accelerometer DOOR1 accZ',\n",
    "        'Accelerometer DOOR2 accX', 'Accelerometer DOOR2 accY', 'Accelerometer DOOR2 accZ',\n",
    "        'Locomotion', 'LL_Left_Arm_Object', 'LL_Right_Arm_Object', 'ML_Both_Arms'\n",
    "        ]]\n",
    "    \n",
    "    # Drop rows where 'LL_Left_Arm', 'LL_Left_Arm_Object', 'LL_Right_Arm', 'LL_Right_Arm_Object', 'ML_Both_Arms' are all 0\n",
    "    # data = data[(data['LL_Left_Arm_Object'] != 0) | (data['LL_Right_Arm_Object'] != 0) | (data['ML_Both_Arms'] != 0)]\n",
    "\n",
    "    # drop rows where 'Locomotion' is 0\n",
    "    data = data[data['Locomotion'] != 0]\n",
    "\n",
    "    # drop the rows with missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # drop rows that contain unwanted records in 'ML_Both_Arms'\n",
    "    data = data[~data['LL_Left_Arm_Object'].isin([301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 318, 319, 320, 321, 322, 323])]\n",
    "\n",
    "    # drop rows that contain unwanted records in 'ML_Both_Arms'\n",
    "    data = data[~data['LL_Right_Arm_Object'].isin([501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521, 522, 523])]\n",
    "\n",
    "    # drop rows that contain unwanted records in 'ML_Both_Arms'\n",
    "    data = data[~data['ML_Both_Arms'].isin([406520, 404520, 406505, 404505, 406519, 404519, 406511, 404511, 406508, 404508, 408512, 407521, 405506])]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset by combinig all files\n",
    "\n",
    "# list all files in dataset folder\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "file_names = os.listdir('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 4 5] S4-ADL1.csv processed\n",
      "[2 1 4] S4-Drill.csv processed\n",
      "[2 1 4 5] S4-ADL2.csv processed\n",
      "[2 5 4 1] S4-ADL3.csv processed\n",
      "[2 1 4] S2-Drill.csv processed\n",
      "[2 1 4 5] S4-ADL4.csv processed\n",
      "[2 1 4 5] S4-ADL5.csv processed\n",
      "[2 1 5 4] S2-ADL4.csv processed\n",
      "[2 1 4 5] S3-ADL4.csv processed\n",
      "[1 2 4 5] S3-ADL5.csv processed\n",
      "[2 1 5 4] S2-ADL5.csv processed\n",
      "[1 2 4 5] S2-ADL1.csv processed\n",
      "[2 1 4 5] S3-ADL1.csv processed\n",
      "[2 1 4] S3-Drill.csv processed\n",
      "[2 1 4 5] S3-ADL2.csv processed\n",
      "[2 1 4 5] S2-ADL2.csv processed\n",
      "[2 5 1 4] S2-ADL3.csv processed\n",
      "[2 1 4 5] S3-ADL3.csv processed\n",
      "[1 2 5 4] S1-ADL2.csv processed\n",
      "[1 2 5 4] S1-ADL3.csv processed\n",
      "[1 2 5 4] S1-ADL1.csv processed\n",
      "[1 2 5 4] S1-ADL4.csv processed\n",
      "[1 2 5 4] S1-ADL5.csv processed\n",
      "[2 1 4] S1-Drill.csv processed\n"
     ]
    }
   ],
   "source": [
    "# creating a training and testing dataset\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "four = 0\n",
    "five = 0\n",
    "\n",
    "for file in file_names:\n",
    "    # process the file\n",
    "    data = process_file('dataset/' + file)\n",
    "    # append the data to the csv file according to file name\n",
    "    # list unique values in 'Locomotion' column\n",
    "    print(data['Locomotion'].unique(), end = ' ')\n",
    "    if file.split('-')[0] == 'S1':\n",
    "        if one == 0:\n",
    "            data.to_csv('S1.csv', index=False)\n",
    "            one = 1\n",
    "        else:\n",
    "            data.to_csv('S1.csv', mode='a', header=False, index=False)\n",
    "    elif file.split('-')[0] == 'S2':\n",
    "        if two == 0:\n",
    "            data.to_csv('S2.csv', index=False)\n",
    "            two = 1\n",
    "        else:\n",
    "            data.to_csv('S2.csv', mode='a', header=False, index=False)\n",
    "    elif file.split('-')[0] == 'S3':\n",
    "        if three == 0:\n",
    "            data.to_csv('S3.csv', index=False)\n",
    "            three = 1\n",
    "        else:\n",
    "            data.to_csv('S3.csv', mode='a', header=False, index=False)\n",
    "    elif file.split('-')[0] == 'S4':\n",
    "        if four == 0:\n",
    "            data.to_csv('S4.csv', index=False)\n",
    "            four = 1\n",
    "        else:\n",
    "            data.to_csv('S4.csv', mode='a', header=False, index=False)\n",
    "    print(file, 'processed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
